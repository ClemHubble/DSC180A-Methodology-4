---
layout: default
title: Home
---

# Fong Vo
UCSD email: fvo@ucsd.edu

**Section:** A12 Quantifying the credibility of large language model outputs  
**Mentor:** Professor Yian Ma

**What is the most interesting topic covered in your domain this quarter?**  
The most interesting topic for me this quarter was model calibration and reliability evaluation. I learned that a model can be accurate overall but still poorly calibrated. In other words, the model's confidence scores don’t always reflect how often it’s actually right. Metrics like Expected Calibration Error (ECE) measure this mismatch between confidence and accuracy. QRC bounds (Quantile Reliability Curves) help visualize and quantify how reliability changes across different confidence levels, and CVaR (Conditional Value at Risk) focuses on the model’s worst-case performance, showing how unreliable it gets on its most uncertain predictions. I found it fascinating how these metrics reveal deeper insights into how trustworthy a model really is, beyond just its accuracy score.  

**Describe a potential investigation you would like to pursue for your Quarter 2 Project.**  
Answer2

**What is a potential change you’d make to the approach taken in your current Quarter 1 Project?**  
Answer3

**What other techniques would you be interested in using in your project?**  
Answer4

